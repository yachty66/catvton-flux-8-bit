{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to quantize the model to 8-bit integer\n",
    "#need to quantize this boy xiaozaa/catvton-flux-alpha and if i have it i can reuse it in the pipeline i have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da6cbf7e1d44ed9b2120db400e9abe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b964334b054ff4a4a28bda0387c8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model quantized and saved successfully!\n",
      "Memory footprint: 11.09 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import FluxTransformer2DModel, BitsAndBytesConfig\n",
    "from transformers import T5EncoderModel\n",
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Configure 8-bit quantization\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,  # Default threshold for 8-bit quantization\n",
    ")\n",
    "\n",
    "# Load and quantize the transformer model\n",
    "transformer_8bit = FluxTransformer2DModel.from_pretrained(\n",
    "    \"xiaozaa/catvton-flux-alpha\",\n",
    "    quantization_config=quant_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"  # Automatically manage model placement\n",
    ")\n",
    "\n",
    "# Save the quantized model\n",
    "output_dir = \"quantized_catvton_flux\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "transformer_8bit.save_pretrained(output_dir)\n",
    "\n",
    "print(\"Model quantized and saved successfully!\")\n",
    "\n",
    "# Check memory footprint\n",
    "print(f\"Memory footprint: {transformer_8bit.get_memory_footprint() / (1024 * 1024 * 1024):.2f} GB\")\n",
    "# Optional: Push to Hub if you want to share it\n",
    "# from huggingface_hub import HfApi\n",
    "# api = HfApi()\n",
    "# api.upload_folder(\n",
    "#     folder_path=\"quantized_catvton_flux\",\n",
    "#     repo_id=\"your-username/quantized-catvton-flux\",\n",
    "#     repo_type=\"model\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/catvton-flux'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "image_path = \"./example/person/example2_model.png\"\n",
    "mask_path = \"./example/person/example2_model_mask.png\"\n",
    "garment_path = \"./example/garment/example2_clothes.png\"\n",
    "output_path_mask = \"./example/person/example2_model_mask.png\"\n",
    "output_path = \"example2.png\"\n",
    "resized_output_path = \"example2_resized.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|█████████████████████████| 2/2 [00:00<00:00, 4758.14it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.43s/it]\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "Loading pipeline components...:  43%|█████▌       | 3/7 [00:00<00:00,  7.23it/s]\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:00<00:00,  9.27it/s]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00,  9.47it/s]\u001b[A\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:00<00:00, 10.27it/s]\n",
      "The module 'FluxTransformer2DModel' has been loaded in `bitsandbytes` 8bit and moving it to cuda via `.to()` is not supported. Module is still on cuda:0.\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py:724: FutureWarning: Passing `image` as torch tensor with value range in [-1,1] is deprecated. The expected value range for image tensor is [0,1] when passing as pytorch tensor or numpy Array. You passed `image` with value range [-1.0,1.0]\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "100%|███████████████████████████████████████████| 50/50 [00:44<00:00,  1.12it/s]\n",
      "Successfully saved garment and try-on images\n",
      "Image Gen Seconds:  62.2\n"
     ]
    }
   ],
   "source": [
    "#need to run this for checking the result:\n",
    "!export HUGGINGFACE_HUB_CACHE=./models\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "image_gen_start_time = time.time()\n",
    "\n",
    "!python tryon_inference_quantized_4_bit.py \\\n",
    "--image {image_path} \\\n",
    "--mask {mask_path} \\\n",
    "--garment {garment_path} \\\n",
    "--seed 4096 \\\n",
    "--output_tryon {output_path} \\\n",
    "# --height 512 \\\n",
    "# --width 256 \\\n",
    "--steps 5\n",
    "\n",
    "image_gen_end_time = time.time()\n",
    "print(\"Image Gen Seconds: \",round((image_gen_end_time - image_gen_start_time),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.29.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. push the model to HF hub\n",
    "2. make a colab with all of the code\n",
    "\"\"\"\n",
    "from huggingface_hub import login\n",
    "from diffusers import FluxTransformer2DModel\n",
    "\n",
    "# Login to Huggingface\n",
    "import os\n",
    "\n",
    "# Set up Hugging Face token\n",
    "os.environ[\"HUGGINGFACE_TOKEN\"] = \"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\"\n",
    "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2141f2896847918f71d190e701d8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f257cfa9bed4a149d2781c24d9397ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model-00001-of-00002.safetensors:   0%|          | 0.00/9.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f09e11fc2bc47c58f8e0bb6ba87b0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model-00002-of-00002.safetensors:   0%|          | 0.00/1.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f58206d85146a0826579b9bc5cb276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/yachty66/8-bit-quantized-catvton-flux/commit/8beea467cde1973aa87a7d2eb37c5a4e03fd36d5', commit_message='Upload 8-bit quantized CatVTON FLUX model', commit_description='', oid='8beea467cde1973aa87a7d2eb37c5a4e03fd36d5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/yachty66/8-bit-quantized-catvton-flux', endpoint='https://huggingface.co', repo_type='model', repo_id='yachty66/8-bit-quantized-catvton-flux'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your local quantized model\n",
    "model = FluxTransformer2DModel.from_pretrained(\n",
    "    \"./quantized_catvton_flux\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Push to your hub repository\n",
    "model.push_to_hub(\n",
    "    \"yachty66/8-bit-quantized-catvton-flux\",\n",
    "    commit_message=\"Upload 8-bit quantized CatVTON FLUX model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
